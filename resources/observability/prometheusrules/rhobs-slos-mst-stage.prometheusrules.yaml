---
$schema: /openshift/prometheus-rule-1.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    prometheus: app-sre
    role: alert-rules
  name: rhobs-slos-mst-stage
spec:
  groups:
  - interval: 2m30s
    name: api-metrics-write-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4w]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        severity: high
        slo: api-metrics-write-availability-slo
  - interval: 30s
    name: api-metrics-write-availability-slo
    rules:
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[5m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[5m]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate5m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[30m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[30m]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate30m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate1h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[2h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[2h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate2h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[6h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[6h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate6h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1d]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate1d
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4d]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-availability-slo
      record: http_requests:burnrate4d
    - alert: APIMetricsWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (14 * (1-0.99)) and http_requests:burnrate1h{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (14 * (1-0.99))
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long: 1h
        severity: high
        short: 5m
        slo: api-metrics-write-availability-slo
    - alert: APIMetricsWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (7 * (1-0.99)) and http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (7 * (1-0.99))
      for: 15m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long: 6h
        severity: high
        short: 30m
        slo: api-metrics-write-availability-slo
    - alert: APIMetricsWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (2 * (1-0.99)) and http_requests:burnrate1d{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (2 * (1-0.99))
      for: 1h
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long: 1d
        severity: warning
        short: 2h
        slo: api-metrics-write-availability-slo
    - alert: APIMetricsWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (1 * (1-0.99)) and http_requests:burnrate4d{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-availability-slo"}
        > (1 * (1-0.99))
      for: 3h
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long: 4d
        severity: warning
        short: 6h
        slo: api-metrics-write-availability-slo
  - interval: 30s
    name: api-metrics-write-availability-slo-generic
    rules:
    - expr: "0.99"
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}
        or vector(0)) / sum(http_requests:increase4w{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{code!~"^4..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}
        or vector(0))
      labels:
        slo: api-metrics-write-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-query-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[4w]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        severity: high
        slo: api-metrics-query-availability-slo
  - interval: 30s
    name: api-metrics-query-availability-slo
    rules:
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[5m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[5m]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate5m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[30m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[30m]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate30m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[1h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[1h]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate1h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[2h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[2h]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate2h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[6h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[6h]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate6h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[1d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[1d]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate1d
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[4d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}[4d]))
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-availability-slo
      record: http_requests:burnrate4d
    - alert: APIMetricsQueryAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (14 * (1-0.99)) and http_requests:burnrate1h{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (14 * (1-0.99))
      for: 2m
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        long: 1h
        severity: high
        short: 5m
        slo: api-metrics-query-availability-slo
    - alert: APIMetricsQueryAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (7 * (1-0.99)) and http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (7 * (1-0.99))
      for: 15m
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        long: 6h
        severity: high
        short: 30m
        slo: api-metrics-query-availability-slo
    - alert: APIMetricsQueryAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (2 * (1-0.99)) and http_requests:burnrate1d{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (2 * (1-0.99))
      for: 1h
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        long: 1d
        severity: warning
        short: 2h
        slo: api-metrics-query-availability-slo
    - alert: APIMetricsQueryAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (1 * (1-0.99)) and http_requests:burnrate4d{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api",slo="api-metrics-query-availability-slo"}
        > (1 * (1-0.99))
      for: 3h
      labels:
        group: metricsv1
        handler: query
        job: observatorium-observatorium-mst-api
        long: 4d
        severity: warning
        short: 6h
        slo: api-metrics-query-availability-slo
  - interval: 30s
    name: api-metrics-query-availability-slo-generic
    rules:
    - expr: "0.99"
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}
        or vector(0)) / sum(http_requests:increase4w{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{code!~"^4..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="query",job="observatorium-observatorium-mst-api"}
        or vector(0))
      labels:
        slo: api-metrics-query-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-query-range-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[4w]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        severity: high
        slo: api-metrics-query-range-availability-slo
  - interval: 30s
    name: api-metrics-query-range-availability-slo
    rules:
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[5m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[5m]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate5m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[30m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[30m]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate30m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[1h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[1h]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate1h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[2h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[2h]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate2h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[6h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[6h]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate6h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[1d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[1d]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate1d
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[4d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}[4d]))
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        slo: api-metrics-query-range-availability-slo
      record: http_requests:burnrate4d
    - alert: APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (14 * (1-0.99)) and http_requests:burnrate1h{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (14 * (1-0.99))
      for: 2m
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        long: 1h
        severity: high
        short: 5m
        slo: api-metrics-query-range-availability-slo
    - alert: APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (7 * (1-0.99)) and http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (7 * (1-0.99))
      for: 15m
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        long: 6h
        severity: high
        short: 30m
        slo: api-metrics-query-range-availability-slo
    - alert: APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (2 * (1-0.99)) and http_requests:burnrate1d{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (2 * (1-0.99))
      for: 1h
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        long: 1d
        severity: warning
        short: 2h
        slo: api-metrics-query-range-availability-slo
    - alert: APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query_range handler is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsQueryRangeAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (1 * (1-0.99)) and http_requests:burnrate4d{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api",slo="api-metrics-query-range-availability-slo"}
        > (1 * (1-0.99))
      for: 3h
      labels:
        group: metricsv1
        handler: query_range
        job: observatorium-observatorium-mst-api
        long: 4d
        severity: warning
        short: 6h
        slo: api-metrics-query-range-availability-slo
  - interval: 30s
    name: api-metrics-query-range-availability-slo-generic
    rules:
    - expr: "0.99"
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}
        or vector(0)) / sum(http_requests:increase4w{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{code!~"^4..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="query_range",job="observatorium-observatorium-mst-api"}
        or vector(0))
      labels:
        slo: api-metrics-query-range-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-rules-raw-write-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[4w]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        slo: api-rules-raw-write-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        severity: high
        slo: api-rules-raw-write-availability-slo
  - interval: 30s
    name: api-rules-raw-write-availability-slo
    rules:
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[5m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[5m]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate5m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[30m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[30m]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate30m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[1h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[1h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate1h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[2h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[2h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate2h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[6h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[6h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate6h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[1d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[1d]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate1d
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[4d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}[4d]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: PUT
        slo: api-rules-raw-write-availability-slo
      record: http_requests:burnrate4d
    - alert: APIRulesRawWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (14 * (1-0.99)) and http_requests:burnrate1h{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (14 * (1-0.99))
      for: 2m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long: 1h
        method: PUT
        severity: high
        short: 5m
        slo: api-rules-raw-write-availability-slo
    - alert: APIRulesRawWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (7 * (1-0.99)) and http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (7 * (1-0.99))
      for: 15m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long: 6h
        method: PUT
        severity: high
        short: 30m
        slo: api-rules-raw-write-availability-slo
    - alert: APIRulesRawWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (2 * (1-0.99)) and http_requests:burnrate1d{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (2 * (1-0.99))
      for: 1h
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long: 1d
        method: PUT
        severity: warning
        short: 2h
        slo: api-rules-raw-write-availability-slo
    - alert: APIRulesRawWriteAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for writes is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawWriteAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (1 * (1-0.99)) and http_requests:burnrate4d{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT",slo="api-rules-raw-write-availability-slo"}
        > (1 * (1-0.99))
      for: 3h
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long: 4d
        method: PUT
        severity: warning
        short: 6h
        slo: api-rules-raw-write-availability-slo
  - interval: 30s
    name: api-rules-raw-write-availability-slo-generic
    rules:
    - expr: "0.99"
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}
        or vector(0)) / sum(http_requests:increase4w{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"})
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"})
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="PUT"}
        or vector(0))
      labels:
        slo: api-rules-raw-write-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-rules-raw-read-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[4w]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-raw-read-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        severity: high
        slo: api-rules-raw-read-availability-slo
  - interval: 30s
    name: api-rules-raw-read-availability-slo
    rules:
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[5m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[5m]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate5m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[30m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[30m]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate30m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[1h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[1h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate1h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[2h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[2h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate2h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[6h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[6h]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate6h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[1d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[1d]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate1d
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[4d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}[4d]))
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-raw-read-availability-slo
      record: http_requests:burnrate4d
    - alert: APIRulesRawReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (14 * (1-0.99)) and http_requests:burnrate1h{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (14 * (1-0.99))
      for: 2m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long: 1h
        method: GET
        severity: high
        short: 5m
        slo: api-rules-raw-read-availability-slo
    - alert: APIRulesRawReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (7 * (1-0.99)) and http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (7 * (1-0.99))
      for: 15m
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long: 6h
        method: GET
        severity: high
        short: 30m
        slo: api-rules-raw-read-availability-slo
    - alert: APIRulesRawReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (2 * (1-0.99)) and http_requests:burnrate1d{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (2 * (1-0.99))
      for: 1h
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long: 1d
        method: GET
        severity: warning
        short: 2h
        slo: api-rules-raw-read-availability-slo
    - alert: APIRulesRawReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules/raw endpoint for reads is burning too much error budget
          to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesRawReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (1 * (1-0.99)) and http_requests:burnrate4d{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-raw-read-availability-slo"}
        > (1 * (1-0.99))
      for: 3h
      labels:
        group: metricsv1
        handler: rules-raw
        job: observatorium-observatorium-mst-api
        long: 4d
        method: GET
        severity: warning
        short: 6h
        slo: api-rules-raw-read-availability-slo
  - interval: 30s
    name: api-rules-raw-read-availability-slo-generic
    rules:
    - expr: "0.99"
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}
        or vector(0)) / sum(http_requests:increase4w{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"})
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"})
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules-raw",job="observatorium-observatorium-mst-api",method="GET"}
        or vector(0))
      labels:
        slo: api-rules-raw-read-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-rules-read-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[4w]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-read-availability-slo
      record: http_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: absent(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        severity: high
        slo: api-rules-read-availability-slo
  - interval: 30s
    name: api-rules-read-availability-slo
    rules:
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[5m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[5m]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate5m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[30m]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[30m]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate30m
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[1h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[1h]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate1h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[2h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[2h]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate2h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[6h]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[6h]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate6h
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[1d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[1d]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate1d
    - expr: sum by(code) (rate(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[4d]))
        / sum by(code) (rate(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}[4d]))
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        method: GET
        slo: api-rules-read-availability-slo
      record: http_requests:burnrate4d
    - alert: APIRulesReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate5m{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (14 * (1-0.99)) and http_requests:burnrate1h{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (14 * (1-0.99))
      for: 2m
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        long: 1h
        method: GET
        severity: high
        short: 5m
        slo: api-rules-read-availability-slo
    - alert: APIRulesReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate30m{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (7 * (1-0.99)) and http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (7 * (1-0.99))
      for: 15m
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        long: 6h
        method: GET
        severity: high
        short: 30m
        slo: api-rules-read-availability-slo
    - alert: APIRulesReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate2h{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (2 * (1-0.99)) and http_requests:burnrate1d{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (2 * (1-0.99))
      for: 1h
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        long: 1d
        method: GET
        severity: warning
        short: 2h
        slo: api-rules-read-availability-slo
    - alert: APIRulesReadAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /rules endpoint is burning too much error budget to guarantee
          availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesReadAvailabilityErrorBudgetBurning
      expr: http_requests:burnrate6h{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (1 * (1-0.99)) and http_requests:burnrate4d{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET",slo="api-rules-read-availability-slo"}
        > (1 * (1-0.99))
      for: 3h
      labels:
        group: metricsv1
        handler: rules
        job: observatorium-observatorium-mst-api
        long: 4d
        method: GET
        severity: warning
        short: 6h
        slo: api-rules-read-availability-slo
  - interval: 30s
    name: api-rules-read-availability-slo-generic
    rules:
    - expr: "0.99"
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_window
    - expr: 1 - sum(http_requests:increase4w{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}
        or vector(0)) / sum(http_requests:increase4w{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"})
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_availability
    - expr: sum(http_requests_total{code!~"^4..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"})
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_requests_total
    - expr: sum(http_requests_total{code=~"^5..$",group="metricsv1",handler="rules",job="observatorium-observatorium-mst-api",method="GET"}
        or vector(0))
      labels:
        slo: api-rules-read-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-rules-sync-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[4w]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-stage
        slo: api-rules-sync-availability-slo
      record: client_api_requests:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: absent(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"})
        == 1
      for: 2m
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-stage
        severity: high
        slo: api-rules-sync-availability-slo
  - interval: 30s
    name: api-rules-sync-availability-slo
    rules:
    - expr: sum by(code) (rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[5m]))
        / sum by(code) (rate(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[5m]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-stage
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate5m
    - expr: sum by(code) (rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[30m]))
        / sum by(code) (rate(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[30m]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-stage
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate30m
    - expr: sum by(code) (rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[1h]))
        / sum by(code) (rate(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[1h]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-stage
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate1h
    - expr: sum by(code) (rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[2h]))
        / sum by(code) (rate(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[2h]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-stage
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate2h
    - expr: sum by(code) (rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[6h]))
        / sum by(code) (rate(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[6h]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-stage
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate6h
    - expr: sum by(code) (rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[1d]))
        / sum by(code) (rate(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[1d]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-stage
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate1d
    - expr: sum by(code) (rate(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[4d]))
        / sum by(code) (rate(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}[4d]))
      labels:
        client: reload
        container: thanos-rule-syncer
        namespace: observatorium-mst-stage
        slo: api-rules-sync-availability-slo
      record: client_api_requests:burnrate4d
    - alert: APIRulesSyncAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: client_api_requests:burnrate5m{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage",slo="api-rules-sync-availability-slo"}
        > (14 * (1-0.99)) and client_api_requests:burnrate1h{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage",slo="api-rules-sync-availability-slo"}
        > (14 * (1-0.99))
      for: 2m
      labels:
        client: reload
        container: thanos-rule-syncer
        long: 1h
        namespace: observatorium-mst-stage
        severity: high
        short: 5m
        slo: api-rules-sync-availability-slo
    - alert: APIRulesSyncAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: client_api_requests:burnrate30m{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage",slo="api-rules-sync-availability-slo"}
        > (7 * (1-0.99)) and client_api_requests:burnrate6h{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage",slo="api-rules-sync-availability-slo"}
        > (7 * (1-0.99))
      for: 15m
      labels:
        client: reload
        container: thanos-rule-syncer
        long: 6h
        namespace: observatorium-mst-stage
        severity: high
        short: 30m
        slo: api-rules-sync-availability-slo
    - alert: APIRulesSyncAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: client_api_requests:burnrate2h{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage",slo="api-rules-sync-availability-slo"}
        > (2 * (1-0.99)) and client_api_requests:burnrate1d{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage",slo="api-rules-sync-availability-slo"}
        > (2 * (1-0.99))
      for: 1h
      labels:
        client: reload
        container: thanos-rule-syncer
        long: 1d
        namespace: observatorium-mst-stage
        severity: warning
        short: 2h
        slo: api-rules-sync-availability-slo
    - alert: APIRulesSyncAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: Thanos Ruler /reload endpoint is burning too much error budget to
          guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIRulesSyncAvailabilityErrorBudgetBurning
      expr: client_api_requests:burnrate6h{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage",slo="api-rules-sync-availability-slo"}
        > (1 * (1-0.99)) and client_api_requests:burnrate4d{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage",slo="api-rules-sync-availability-slo"}
        > (1 * (1-0.99))
      for: 3h
      labels:
        client: reload
        container: thanos-rule-syncer
        long: 4d
        namespace: observatorium-mst-stage
        severity: warning
        short: 6h
        slo: api-rules-sync-availability-slo
  - interval: 30s
    name: api-rules-sync-availability-slo-generic
    rules:
    - expr: "0.99"
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_window
    - expr: 1 - sum(client_api_requests:increase4w{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}
        or vector(0)) / sum(client_api_requests:increase4w{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"})
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_availability
    - expr: sum(client_api_requests_total{client="reload",code!~"^4..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"})
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_requests_total
    - expr: sum(client_api_requests_total{client="reload",code=~"^5..$",container="thanos-rule-syncer",namespace="observatorium-mst-stage"}
        or vector(0))
      labels:
        slo: api-rules-sync-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-alerting-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"}[4w]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-stage
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: absent(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"})
        == 1
      for: 2m
      labels:
        container: thanos-rule
        namespace: observatorium-mst-stage
        severity: high
        slo: api-alerting-availability-slo
  - interval: 30s
    name: api-alerting-availability-slo
    rules:
    - expr: sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-stage"}[5m]))
        / sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"}[5m]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-stage
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate5m
    - expr: sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-stage"}[30m]))
        / sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"}[30m]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-stage
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate30m
    - expr: sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-stage"}[1h]))
        / sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"}[1h]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-stage
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate1h
    - expr: sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-stage"}[2h]))
        / sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"}[2h]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-stage
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate2h
    - expr: sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-stage"}[6h]))
        / sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"}[6h]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-stage
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate6h
    - expr: sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-stage"}[1d]))
        / sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"}[1d]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-stage
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate1d
    - expr: sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-stage"}[4d]))
        / sum by(code) (rate(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"}[4d]))
      labels:
        container: thanos-rule
        namespace: observatorium-mst-stage
        slo: api-alerting-availability-slo
      record: thanos_alert_sender_alerts_dropped:burnrate4d
    - alert: APIAlertmanagerAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: thanos_alert_sender_alerts_dropped:burnrate5m{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage",slo="api-alerting-availability-slo"}
        > (14 * (1-0.99)) and thanos_alert_sender_alerts_dropped:burnrate1h{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage",slo="api-alerting-availability-slo"}
        > (14 * (1-0.99))
      for: 2m
      labels:
        container: thanos-rule
        long: 1h
        namespace: observatorium-mst-stage
        severity: high
        short: 5m
        slo: api-alerting-availability-slo
    - alert: APIAlertmanagerAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: thanos_alert_sender_alerts_dropped:burnrate30m{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage",slo="api-alerting-availability-slo"}
        > (7 * (1-0.99)) and thanos_alert_sender_alerts_dropped:burnrate6h{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage",slo="api-alerting-availability-slo"}
        > (7 * (1-0.99))
      for: 15m
      labels:
        container: thanos-rule
        long: 6h
        namespace: observatorium-mst-stage
        severity: high
        short: 30m
        slo: api-alerting-availability-slo
    - alert: APIAlertmanagerAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: thanos_alert_sender_alerts_dropped:burnrate2h{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage",slo="api-alerting-availability-slo"}
        > (2 * (1-0.99)) and thanos_alert_sender_alerts_dropped:burnrate1d{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage",slo="api-alerting-availability-slo"}
        > (2 * (1-0.99))
      for: 1h
      labels:
        container: thanos-rule
        long: 1d
        namespace: observatorium-mst-stage
        severity: warning
        short: 2h
        slo: api-alerting-availability-slo
    - alert: APIAlertmanagerAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Thanos Rule failing to send alerts to Alertmanager and is burning
          too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerAvailabilityErrorBudgetBurning
      expr: thanos_alert_sender_alerts_dropped:burnrate6h{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage",slo="api-alerting-availability-slo"}
        > (1 * (1-0.99)) and thanos_alert_sender_alerts_dropped:burnrate4d{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage",slo="api-alerting-availability-slo"}
        > (1 * (1-0.99))
      for: 3h
      labels:
        container: thanos-rule
        long: 4d
        namespace: observatorium-mst-stage
        severity: warning
        short: 6h
        slo: api-alerting-availability-slo
  - interval: 30s
    name: api-alerting-availability-slo-generic
    rules:
    - expr: "0.99"
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_window
    - expr: 1 - sum(thanos_alert_sender_alerts_dropped:increase4w{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-stage"}
        or vector(0)) / sum(thanos_alert_sender_alerts_dropped:increase4w{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"})
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_availability
    - expr: sum(thanos_alert_sender_alerts_dropped_total{code!~"^4..$",container="thanos-rule",namespace="observatorium-mst-stage"})
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_requests_total
    - expr: sum(thanos_alert_sender_alerts_dropped_total{code=~"^5..$",container="thanos-rule",namespace="observatorium-mst-stage"}
        or vector(0))
      labels:
        slo: api-alerting-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-alerting-notif-availability-slo-increase
    rules:
    - expr: sum by(code) (increase(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[4w]))
      labels:
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: absent(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        severity: high
        slo: api-alerting-notif-availability-slo
  - interval: 30s
    name: api-alerting-notif-availability-slo
    rules:
    - expr: sum by(code) (rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[5m]))
        / sum by(code) (rate(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[5m]))
      labels:
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate5m
    - expr: sum by(code) (rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[30m]))
        / sum by(code) (rate(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[30m]))
      labels:
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate30m
    - expr: sum by(code) (rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[1h]))
        / sum by(code) (rate(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[1h]))
      labels:
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate1h
    - expr: sum by(code) (rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[2h]))
        / sum by(code) (rate(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[2h]))
      labels:
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate2h
    - expr: sum by(code) (rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[6h]))
        / sum by(code) (rate(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[6h]))
      labels:
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate6h
    - expr: sum by(code) (rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[1d]))
        / sum by(code) (rate(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[1d]))
      labels:
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate1d
    - expr: sum by(code) (rate(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[4d]))
        / sum by(code) (rate(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}[4d]))
      labels:
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        slo: api-alerting-notif-availability-slo
      record: alertmanager_notifications_failed:burnrate4d
    - alert: APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: alertmanager_notifications_failed:burnrate5m{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (14 * (1-0.99)) and alertmanager_notifications_failed:burnrate1h{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (14 * (1-0.99))
      for: 2m
      labels:
        long: 1h
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        severity: high
        short: 5m
        slo: api-alerting-notif-availability-slo
    - alert: APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: alertmanager_notifications_failed:burnrate30m{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (7 * (1-0.99)) and alertmanager_notifications_failed:burnrate6h{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (7 * (1-0.99))
      for: 15m
      labels:
        long: 6h
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        severity: high
        short: 30m
        slo: api-alerting-notif-availability-slo
    - alert: APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: alertmanager_notifications_failed:burnrate2h{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (2 * (1-0.99)) and alertmanager_notifications_failed:burnrate1d{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (2 * (1-0.99))
      for: 1h
      labels:
        long: 1d
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        severity: warning
        short: 2h
        slo: api-alerting-notif-availability-slo
    - alert: APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API Alertmanager failing to deliver alerts to upstream targets and
          is burning too much error budget to guarantee availability SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIAlertmanagerNotificationsAvailabilityErrorBudgetBurning
      expr: alertmanager_notifications_failed:burnrate6h{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (1 * (1-0.99)) and alertmanager_notifications_failed:burnrate4d{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager",slo="api-alerting-notif-availability-slo"}
        > (1 * (1-0.99))
      for: 3h
      labels:
        long: 4d
        namespace: observatorium-mst-stage
        service: observatorium-alertmanager
        severity: warning
        short: 6h
        slo: api-alerting-notif-availability-slo
  - interval: 30s
    name: api-alerting-notif-availability-slo-generic
    rules:
    - expr: "0.99"
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_window
    - expr: 1 - sum(alertmanager_notifications_failed:increase4w{code=~"^5..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}
        or vector(0)) / sum(alertmanager_notifications_failed:increase4w{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"})
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_availability
    - expr: sum(alertmanager_notifications_failed_total{code!~"^4..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"})
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_requests_total
    - expr: sum(alertmanager_notifications_failed_total{code=~"^5..$",namespace="observatorium-mst-stage",service="observatorium-alertmanager"}
        or vector(0))
      labels:
        slo: api-alerting-notif-availability-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-write-latency-slo-increase
    rules:
    - expr: sum by(code) (increase(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4w]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:increase4w
    - expr: sum by(code) (increase(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[4w]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        le: "5"
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: absent(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        severity: high
        slo: api-metrics-write-latency-slo
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: absent(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"})
        == 1
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        le: "5"
        severity: high
        slo: api-metrics-write-latency-slo
  - interval: 30s
    name: api-metrics-write-latency-slo
    rules:
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[5m]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[5m])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[5m]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate5m
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[30m]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[30m])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[30m]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate30m
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1h]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[1h])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate1h
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[2h]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[2h])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[2h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate2h
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[6h]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[6h])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[6h]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate6h
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1d]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[1d])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[1d]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate1d
    - expr: (sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4d]))
        - sum(rate(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"}[4d])))
        / sum(rate(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"}[4d]))
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        slo: api-metrics-write-latency-slo
      record: http_request_duration_seconds:burnrate4d
    - alert: APIMetricsWriteLatencyErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: http_request_duration_seconds:burnrate5m{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (14 * (1-0.9)) and http_request_duration_seconds:burnrate1h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (14 * (1-0.9))
      for: 2m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long: 1h
        severity: high
        short: 5m
        slo: api-metrics-write-latency-slo
    - alert: APIMetricsWriteLatencyErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: http_request_duration_seconds:burnrate30m{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (7 * (1-0.9)) and http_request_duration_seconds:burnrate6h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (7 * (1-0.9))
      for: 15m
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long: 6h
        severity: high
        short: 30m
        slo: api-metrics-write-latency-slo
    - alert: APIMetricsWriteLatencyErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: http_request_duration_seconds:burnrate2h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (2 * (1-0.9)) and http_request_duration_seconds:burnrate1d{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (2 * (1-0.9))
      for: 1h
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long: 1d
        severity: warning
        short: 2h
        slo: api-metrics-write-latency-slo
    - alert: APIMetricsWriteLatencyErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /receive handler is burning too much error budget to guarantee
          latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsWriteLatencyErrorBudgetBurning
      expr: http_request_duration_seconds:burnrate6h{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (1 * (1-0.9)) and http_request_duration_seconds:burnrate4d{group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",slo="api-metrics-write-latency-slo"}
        > (1 * (1-0.9))
      for: 3h
      labels:
        group: metricsv1
        handler: receive
        job: observatorium-observatorium-mst-api
        long: 4d
        severity: warning
        short: 6h
        slo: api-metrics-write-latency-slo
  - interval: 30s
    name: api-metrics-write-latency-slo-generic
    rules:
    - expr: "0.9"
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_window
    - expr: sum(http_request_duration_seconds:increase4w{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5",slo="api-metrics-write-latency-slo"}
        or vector(0)) / sum(http_request_duration_seconds:increase4w{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="",slo="api-metrics-write-latency-slo"})
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_availability
    - expr: sum(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_requests_total
    - expr: sum(http_request_duration_seconds_count{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api"})
        - sum(http_request_duration_seconds_bucket{code=~"^2..$",group="metricsv1",handler="receive",job="observatorium-observatorium-mst-api",le="5"})
      labels:
        slo: api-metrics-write-latency-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-read-1M-latency-slo-increase
    rules:
    - expr: sum by(code) (increase(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4w]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - expr: sum by(code) (increase(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4w]))
      labels:
        le: "10"
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: high
        slo: api-metrics-read-1M-latency-slo
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
        == 1
      for: 2m
      labels:
        le: "10"
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: high
        slo: api-metrics-read-1M-latency-slo
  - interval: 30s
    name: api-metrics-read-1M-latency-slo
    rules:
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[5m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[5m])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[5m]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate5m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[30m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[30m])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[30m]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate30m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1h])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1h]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[2h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[2h])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[2h]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate2h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[6h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[6h])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[6h]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate6h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1d])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1d]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1d
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4d])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4d]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-1M-latency-slo
      record: up_custom_query_duration_seconds:burnrate4d
    - alert: APIMetricsReadLatency1MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate5m{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (14 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1h{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (14 * (1-0.9))
      for: 2m
      labels:
        long: 1h
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: high
        short: 5m
        slo: api-metrics-read-1M-latency-slo
    - alert: APIMetricsReadLatency1MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate30m{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (7 * (1-0.9)) and up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (7 * (1-0.9))
      for: 15m
      labels:
        long: 6h
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: high
        short: 30m
        slo: api-metrics-read-1M-latency-slo
    - alert: APIMetricsReadLatency1MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate2h{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (2 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1d{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (2 * (1-0.9))
      for: 1h
      labels:
        long: 1d
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: warning
        short: 2h
        slo: api-metrics-read-1M-latency-slo
    - alert: APIMetricsReadLatency1MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 1M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency1MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (1 * (1-0.9)) and up_custom_query_duration_seconds:burnrate4d{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        > (1 * (1-0.9))
      for: 3h
      labels:
        long: 4d
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: warning
        short: 6h
        slo: api-metrics-read-1M-latency-slo
  - interval: 30s
    name: api-metrics-read-1M-latency-slo-generic
    rules:
    - expr: "0.9"
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_window
    - expr: sum(up_custom_query_duration_seconds:increase4w{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"}
        or vector(0)) / sum(up_custom_query_duration_seconds:increase4w{code=~"^2..$",le="",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-1M-latency-slo"})
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_availability
    - expr: sum(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_requests_total
    - expr: sum(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
        - sum(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="10",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
      labels:
        slo: api-metrics-read-1M-latency-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-read-10M-latency-slo-increase
    rules:
    - expr: sum by(code) (increase(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[4w]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - expr: sum by(code) (increase(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[4w]))
      labels:
        le: "30"
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        severity: high
        slo: api-metrics-read-10M-latency-slo
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"})
        == 1
      for: 2m
      labels:
        le: "30"
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        severity: high
        slo: api-metrics-read-10M-latency-slo
  - interval: 30s
    name: api-metrics-read-10M-latency-slo
    rules:
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[5m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[5m])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[5m]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate5m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[30m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[30m])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[30m]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate30m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[1h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[1h])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[1h]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[2h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[2h])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[2h]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate2h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[6h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[6h])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[6h]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate6h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[1d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[1d])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[1d]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1d
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[4d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[4d])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"}[4d]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        slo: api-metrics-read-10M-latency-slo
      record: up_custom_query_duration_seconds:burnrate4d
    - alert: APIMetricsReadLatency10MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate5m{namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (14 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1h{namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (14 * (1-0.9))
      for: 2m
      labels:
        long: 1h
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        severity: high
        short: 5m
        slo: api-metrics-read-10M-latency-slo
    - alert: APIMetricsReadLatency10MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate30m{namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (7 * (1-0.9)) and up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (7 * (1-0.9))
      for: 15m
      labels:
        long: 6h
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        severity: high
        short: 30m
        slo: api-metrics-read-10M-latency-slo
    - alert: APIMetricsReadLatency10MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate2h{namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (2 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1d{namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (2 * (1-0.9))
      for: 1h
      labels:
        long: 1d
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        severity: warning
        short: 2h
        slo: api-metrics-read-10M-latency-slo
    - alert: APIMetricsReadLatency10MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency10MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (1 * (1-0.9)) and up_custom_query_duration_seconds:burnrate4d{namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        > (1 * (1-0.9))
      for: 3h
      labels:
        long: 4d
        namespace: observatorium-mst-stage
        query: query-path-sli-10M-samples
        severity: warning
        short: 6h
        slo: api-metrics-read-10M-latency-slo
  - interval: 30s
    name: api-metrics-read-10M-latency-slo-generic
    rules:
    - expr: "0.9"
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_window
    - expr: sum(up_custom_query_duration_seconds:increase4w{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"}
        or vector(0)) / sum(up_custom_query_duration_seconds:increase4w{code=~"^2..$",le="",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples",slo="api-metrics-read-10M-latency-slo"})
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_availability
    - expr: sum(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"})
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_requests_total
    - expr: sum(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"})
        - sum(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="30",namespace="observatorium-mst-stage",query="query-path-sli-10M-samples"})
      labels:
        slo: api-metrics-read-10M-latency-slo
      record: pyrra_errors_total
  - interval: 2m30s
    name: api-metrics-read-100M-latency-slo-increase
    rules:
    - expr: sum by(code) (increase(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4w]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - expr: sum by(code) (increase(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4w]))
      labels:
        le: "120"
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:increase4w
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
        == 1
      for: 2m
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: high
        slo: api-metrics-read-100M-latency-slo
    - alert: SLOMetricAbsent
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: absent(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
        == 1
      for: 2m
      labels:
        le: "120"
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: high
        slo: api-metrics-read-100M-latency-slo
  - interval: 30s
    name: api-metrics-read-100M-latency-slo
    rules:
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[5m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[5m])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[5m]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate5m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[30m]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[30m])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[30m]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate30m
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1h])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1h]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[2h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[2h])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[2h]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate2h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[6h]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[6h])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[6h]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate6h
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1d])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[1d]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate1d
    - expr: (sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4d]))
        - sum(rate(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4d])))
        / sum(rate(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"}[4d]))
      labels:
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        slo: api-metrics-read-100M-latency-slo
      record: up_custom_query_duration_seconds:burnrate4d
    - alert: APIMetricsReadLatency100MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate5m{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (14 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1h{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (14 * (1-0.9))
      for: 2m
      labels:
        long: 1h
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: high
        short: 5m
        slo: api-metrics-read-100M-latency-slo
    - alert: APIMetricsReadLatency100MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate30m{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (7 * (1-0.9)) and up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (7 * (1-0.9))
      for: 15m
      labels:
        long: 6h
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: high
        short: 30m
        slo: api-metrics-read-100M-latency-slo
    - alert: APIMetricsReadLatency100MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate2h{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (2 * (1-0.9)) and up_custom_query_duration_seconds:burnrate1d{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (2 * (1-0.9))
      for: 1h
      labels:
        long: 1d
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: warning
        short: 2h
        slo: api-metrics-read-100M-latency-slo
    - alert: APIMetricsReadLatency100MErrorBudgetBurning
      annotations:
        dashboard: https://grafana.app-sre.devshift.net/d/92520ea4d6976f30d1618164e186ef9b/mst-stage-slos?orgId=1&refresh=10s&var-datasource=app-sre-stage-01-prometheus&var-namespace={{$labels.namespace}}&var-job=All&var-pod=All&var-interval=5m
        message: API /query endpoint is burning too much error budget for 100M samples,
          to guarantee latency SLOs.
        runbook: https://github.com/rhobs/configuration/blob/main/docs/sop/observatorium.md#APIMetricsReadLatency100MErrorBudgetBurning
      expr: up_custom_query_duration_seconds:burnrate6h{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (1 * (1-0.9)) and up_custom_query_duration_seconds:burnrate4d{namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        > (1 * (1-0.9))
      for: 3h
      labels:
        long: 4d
        namespace: observatorium-mst-stage
        query: query-path-sli-1M-samples
        severity: warning
        short: 6h
        slo: api-metrics-read-100M-latency-slo
  - interval: 30s
    name: api-metrics-read-100M-latency-slo-generic
    rules:
    - expr: "0.9"
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_objective
    - expr: 2419200
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_window
    - expr: sum(up_custom_query_duration_seconds:increase4w{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"}
        or vector(0)) / sum(up_custom_query_duration_seconds:increase4w{code=~"^2..$",le="",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples",slo="api-metrics-read-100M-latency-slo"})
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_availability
    - expr: sum(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_requests_total
    - expr: sum(up_custom_query_duration_seconds_count{code=~"^2..$",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
        - sum(up_custom_query_duration_seconds_bucket{code=~"^2..$",le="120",namespace="observatorium-mst-stage",query="query-path-sli-1M-samples"})
      labels:
        slo: api-metrics-read-100M-latency-slo
      record: pyrra_errors_total
